"""
Mejora de Transcripciones con Gemini - VERSI√ìN PARALELA
========================================================
Procesa m√∫ltiples transcripciones simult√°neamente con ThreadPoolExecutor.
Reanuda autom√°ticamente (salta archivos ya procesados).
"""

import json
import os
import time
import re
import threading
import google.generativeai as genai
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

# ============================================================================
# CONFIGURACI√ìN
# ============================================================================

BASE_DIR = Path(r"C:\Users\rodri\Documents\codigo-WC\eva")
INPUT_DIR = BASE_DIR / "transcripciones"
OUTPUT_DIR = BASE_DIR / "transcripciones_mejoradas"
REPORTE_DIR = BASE_DIR / "reportes" / "mejora_gemini"

from config import api_key
API_KEY = api_key

MODEL_NAME = "gemini-2.0-flash-lite"
MAX_WORKERS = 5          # Hilos concurrentes
DELAY_BETWEEN_CALLS = 0.3  # Delay por worker (total ~15 req/s con 5 workers)
MAX_RETRIES = 3

# Lock para prints y estad√≠sticas
print_lock = threading.Lock()
stats_lock = threading.Lock()
stats = defaultdict(int)
procesados_count = 0

# ============================================================================
# PROMPT
# ============================================================================

PROMPT_MEJORA = """Eres un experto en correcci√≥n y mejora de transcripciones autom√°ticas de un call center de ventas de Movistar Argentina (Mendoza).

## TRANSCRIPCI√ìN ORIGINAL (generada por WhisperX, puede tener errores):
{transcripcion}

## TAREA
Analiza y mejora esta transcripci√≥n. Debes:

1. **CORREGIR ERRORES DE WHISPER**: Whisper suele transcribir mal:
   - "gigas" ‚Üí aparece como "llenas", "llegas", "libras", "sigas", "chicas", etc.
   - Nombres propios mal escritos
   - Palabras cortadas o sin sentido
   - "fibra" ‚Üí puede aparecer como "libra", "fila", etc.
   - N√∫meros y planes (ej: "plan de 15", "plan de 20 gigas")

2. **IDENTIFICAR ROLES**: Determina qui√©n es el AGENTE (vendedor Movistar) y qui√©n es el CLIENTE.
   - AGENTE: Se presenta ("Habla con X de Movistar"), ofrece productos, valida datos
   - CLIENTE: Responde, pregunta precios, acepta/rechaza

3. **CLASIFICAR LA LLAMADA**:
   - Tipo: VENTA | SEGUIMIENTO | RECLAMO | SIN_CONTACTO | NO_ATENDIDA
   - Resultado: VENTA_EXITOSA | RECHAZO | PENDIENTE | SIN_DECISION | CORTE

4. **PRODUCTOS MENCIONADOS**: Lista los planes/productos ofrecidos (ej: "plan 15gb", "fibra 100mb", "combo fibra+m√≥vil")

RESPONDE SOLO con este JSON (sin texto adicional, sin markdown):
{{
  "conversacion_mejorada": [
    {{
      "hablante": "AGENTE" o "CLIENTE",
      "inicio": <n√∫mero>,
      "fin": <n√∫mero>,
      "texto": "<texto corregido y mejorado>"
    }}
  ],
  "analisis": {{
    "agente_detectado": "Hablante A" o "Hablante B",
    "confianza_roles": "ALTA" | "MEDIA" | "BAJA",
    "tipo_llamada": "VENTA" | "SEGUIMIENTO" | "RECLAMO" | "SIN_CONTACTO" | "NO_ATENDIDA",
    "resultado": "VENTA_EXITOSA" | "RECHAZO" | "PENDIENTE" | "SIN_DECISION" | "CORTE",
    "productos_mencionados": [],
    "plan_vendido": null,
    "incluye_fibra": false,
    "calidad_transcripcion_original": "BUENA" | "REGULAR" | "MALA",
    "correcciones_realizadas": "<breve descripci√≥n de qu√© se corrigi√≥>"
  }}
}}
"""

# ============================================================================
# FUNCIONES
# ============================================================================

def crear_modelo():
    """Crea una instancia del modelo Gemini."""
    return genai.GenerativeModel(MODEL_NAME)


def formatear_transcripcion(conversacion):
    lineas = []
    for seg in conversacion:
        hablante = seg.get('hablante', 'Desconocido')
        texto = seg.get('texto', '')
        inicio = seg.get('inicio', 0)
        fin = seg.get('fin', 0)
        lineas.append(f"[{inicio:.1f}s-{fin:.1f}s] {hablante}: {texto}")
    return '\n'.join(lineas)


def limpiar_json_response(texto):
    texto = texto.strip()
    if texto.startswith('```json'):
        texto = texto[7:]
    if texto.startswith('```'):
        texto = texto[3:]
    if texto.endswith('```'):
        texto = texto[:-3]
    return texto.strip()


def procesar_con_gemini(model, transcripcion_text):
    prompt = PROMPT_MEJORA.format(transcripcion=transcripcion_text)
    
    for intento in range(MAX_RETRIES):
        try:
            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.2,
                    max_output_tokens=8192,
                )
            )
            
            texto_resp = limpiar_json_response(response.text)
            
            try:
                return json.loads(texto_resp)
            except json.JSONDecodeError:
                ultimo = texto_resp.rfind('}')
                if ultimo > 0:
                    depth = 0
                    for i, c in enumerate(texto_resp):
                        if c == '{':
                            depth += 1
                        elif c == '}':
                            depth -= 1
                            if depth == 0:
                                return json.loads(texto_resp[:i+1])
                raise
                    
        except json.JSONDecodeError as e:
            with print_lock:
                print(f"      ‚ö†Ô∏è JSON inv√°lido (intento {intento+1}): {str(e)[:50]}")
            if intento < MAX_RETRIES - 1:
                time.sleep(2)
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "quota" in error_msg.lower() or "resource" in error_msg.lower():
                wait = 30 * (intento + 1)
                with print_lock:
                    print(f"      ‚ö†Ô∏è Rate limit, esperando {wait}s...")
                time.sleep(wait)
            else:
                with print_lock:
                    print(f"      ‚ùå Error Gemini (intento {intento+1}): {str(e)[:60]}")
                if intento < MAX_RETRIES - 1:
                    time.sleep(3)
    
    return None


def procesar_archivo(json_path, total, worker_id):
    """Procesa un archivo de transcripci√≥n (thread-safe)."""
    global procesados_count
    
    # Usar modelo compartido (genai ya configurado en main)
    model = crear_modelo()
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        conversacion = data.get('conversacion', [])
        if not conversacion or len(conversacion) < 2:
            with stats_lock:
                stats['skip'] += 1
                procesados_count += 1
                num = procesados_count
            with print_lock:
                print(f"  [{num}/{total}] {json_path.stem[:45]}... ‚è≠Ô∏è Sin conversaci√≥n suficiente")
            return
        
        textos_reales = [s for s in conversacion if len(s.get('texto', '').strip()) > 3]
        if len(textos_reales) < 3:
            with stats_lock:
                stats['skip'] += 1
                procesados_count += 1
                num = procesados_count
            with print_lock:
                print(f"  [{num}/{total}] {json_path.stem[:45]}... ‚è≠Ô∏è Muy corta")
            return
        
        texto_transcripcion = formatear_transcripcion(conversacion)
        
        # Peque√±o delay escalonado por worker para no bombardear la API
        time.sleep(DELAY_BETWEEN_CALLS * worker_id)
        
        resultado_gemini = procesar_con_gemini(model, texto_transcripcion)
        
        if not resultado_gemini:
            with stats_lock:
                stats['error'] += 1
                procesados_count += 1
                num = procesados_count
            with print_lock:
                print(f"  [{num}/{total}] {json_path.stem[:45]}... ‚ùå Sin respuesta")
            return
        
        # Construir archivo mejorado
        data_mejorada = data.copy()
        analisis = resultado_gemini.get('analisis', {})
        data_mejorada['mejora_gemini'] = {
            'analisis': analisis,
            'fecha_mejora': datetime.now().isoformat(),
            'modelo': MODEL_NAME
        }
        
        conv_mejorada = resultado_gemini.get('conversacion_mejorada', [])
        if conv_mejorada and len(conv_mejorada) > 0:
            data_mejorada['conversacion_original'] = data.get('conversacion', [])
            data_mejorada['conversacion'] = conv_mejorada
            data_mejorada['transcripcion_completa'] = ' '.join(
                seg.get('texto', '') for seg in conv_mejorada
            )
        
        output_name = json_path.name.replace('_transcripcion.json', '_mejorado.json')
        output_path = OUTPUT_DIR / output_name
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data_mejorada, f, ensure_ascii=False, indent=2)
        
        tipo = analisis.get('tipo_llamada', '?')
        resultado = analisis.get('resultado', '?')
        calidad = analisis.get('calidad_transcripcion_original', '?')
        
        with stats_lock:
            stats['ok'] += 1
            procesados_count += 1
            num = procesados_count
        with print_lock:
            print(f"  [{num}/{total}] {json_path.stem[:45]}... ‚úÖ {tipo} | {resultado} | {calidad}")
        
    except Exception as e:
        with stats_lock:
            stats['error'] += 1
            procesados_count += 1
            num = procesados_count
        with print_lock:
            print(f"  [{num}/{total}] {json_path.stem[:45]}... ‚ùå {str(e)[:50]}")


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("=" * 70)
    print("  ü§ñ MEJORA DE TRANSCRIPCIONES CON GEMINI (PARALELO)")
    print("=" * 70)
    print(f"  üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"  üìÇ Input:  {INPUT_DIR}")
    print(f"  üìÇ Output: {OUTPUT_DIR}")
    print(f"  üß† Modelo: {MODEL_NAME}")
    print(f"  ‚ö° Workers: {MAX_WORKERS}")
    print("=" * 70)
    
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    REPORTE_DIR.mkdir(parents=True, exist_ok=True)
    
    # Listar transcripciones
    todos = sorted(INPUT_DIR.glob("*_transcripcion.json"))
    print(f"\n  üìä Transcripciones disponibles: {len(todos)}")
    
    # Saltar ya procesadas
    ya_mejorados = set()
    if OUTPUT_DIR.exists():
        for f in OUTPUT_DIR.iterdir():
            if f.name.endswith('_mejorado.json'):
                nombre_orig = f.name.replace('_mejorado.json', '_transcripcion.json')
                ya_mejorados.add(nombre_orig)
    
    pendientes = [f for f in todos if f.name not in ya_mejorados]
    print(f"  ‚úÖ Ya mejoradas: {len(ya_mejorados)}")
    print(f"  ‚è≥ Pendientes: {len(pendientes)}")
    
    if not pendientes:
        print("\n  ‚úÖ ¬°Todas las transcripciones ya est√°n mejoradas!")
        return
    
    total = len(pendientes)
    print(f"\n  üöÄ Iniciando mejora de {total} con {MAX_WORKERS} workers...\n")
    
    # Configurar Gemini UNA sola vez
    genai.configure(api_key=API_KEY)
    
    inicio = datetime.now()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = []
        for idx, json_path in enumerate(pendientes):
            worker_id = idx % MAX_WORKERS
            future = executor.submit(procesar_archivo, json_path, total, worker_id)
            futures.append(future)
            # Peque√±o delay entre submits para escalonar
            time.sleep(0.1)
        
        # Esperar todos
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                with print_lock:
                    print(f"  ‚ùå Error inesperado: {e}")
    
    elapsed = (datetime.now() - inicio).total_seconds()
    
    print(f"\n{'='*70}")
    print(f"  üéâ PROCESO COMPLETADO")
    print(f"{'='*70}")
    print(f"  ‚úÖ Mejoradas: {stats['ok']}")
    print(f"  ‚è≠Ô∏è Saltadas:  {stats['skip']}")
    print(f"  ‚ùå Errores:   {stats['error']}")
    print(f"  ‚è±Ô∏è Tiempo:    {elapsed/60:.1f} minutos")
    print(f"  ‚ö° Velocidad: {stats['ok']/(elapsed/60):.0f} archivos/min" if elapsed > 0 else "")
    print(f"  üìÇ Salida:    {OUTPUT_DIR}")
    print(f"{'='*70}")
    
    # Guardar reporte
    reporte = {
        "fecha": datetime.now().isoformat(),
        "modelo": MODEL_NAME,
        "workers": MAX_WORKERS,
        "total_procesados": sum(stats.values()),
        "estadisticas": dict(stats),
        "tiempo_minutos": round(elapsed / 60, 1)
    }
    reporte_path = REPORTE_DIR / f"reporte_mejora_parallel_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(reporte_path, 'w', encoding='utf-8') as f:
        json.dump(reporte, f, ensure_ascii=False, indent=2)
    print(f"  üìÑ Reporte: {reporte_path}")


if __name__ == "__main__":
    main()
